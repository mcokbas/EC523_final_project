{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from pathlib import Path\n",
    "from model import DnCNN\n",
    "import data_generator as dg\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import cv2\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "import glob\n",
    "from noise_model import poissonpoissonnoise as nm\n",
    "import datetime\n",
    "from vgg import Vgg16\n",
    "from torchvision import transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_WEIGHT = 1e5\n",
    "CONTENT_WEIGHT = 1e0\n",
    "\n",
    "# manualSeed = 999\n",
    "# # manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "# print(\"Random Seed: \", manualSeed)\n",
    "# random.seed(manualSeed)\n",
    "# np.random.seed(manualSeed)\n",
    "# torch.manual_seed(manualSeed)\n",
    "def gram(x):\n",
    "    (bs, ch, h, w) = x.size()\n",
    "    f = x.view(bs, ch, w*h)\n",
    "    f_T = f.transpose(1, 2)\n",
    "    G = f.bmm(f_T) / (ch * h * w)\n",
    "    return G\n",
    "\n",
    "def _tensor_transform():\n",
    "    return transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def save_model(net: nn.Module, model_save_dir, step, dose_total):\n",
    "    \"\"\"\n",
    "    Save the trained model.\n",
    "\n",
    "    Args:\n",
    "        net: trained model.\n",
    "        model_save_dir: saved model directory.\n",
    "        step: checkpoint.\n",
    "    \"\"\"\n",
    "    model_save_dir = Path(model_save_dir) / \"dose{}\".format(str(int(dose_total)))\n",
    "    if not Path(model_save_dir).exists():\n",
    "        Path.mkdir(model_save_dir)\n",
    "    model_path = Path(model_save_dir) / \"{}.pth\".format(step + 1)\n",
    "\n",
    "    torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print(\"Saved model checkpoints {} into {}\".format(step + 1, model_save_dir))\n",
    "\n",
    "\n",
    "def restore_model(resume_iters, model_save_dir, net: nn.Module, train=True):\n",
    "    \"\"\"\n",
    "    Restore the trained model.\n",
    "\n",
    "    Args:\n",
    "        resume_iters: the iteration to be loaded.\n",
    "        model_save_dir: the directory for saving the model.\n",
    "        net: the model instance to be loaded.\n",
    "        train: if True, then the model is set to training;\n",
    "               else set it to test.\n",
    "\n",
    "    Returns:\n",
    "        net: loaded model instance.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Loading the trained model from step {}\".format(resume_iters))\n",
    "    model_path = Path(model_save_dir) / \"{}.pth\".format(resume_iters)\n",
    "\n",
    "    # Restore the model.\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    if train:\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "class LossFunc(nn.Module):\n",
    "    def __init__(self, reduction=\"sum\"):\n",
    "        super(LossFunc, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.mse_loss = nn.MSELoss(reduction=reduction)\n",
    "        # TODO: to add TV loss.\n",
    "        # self.tv_loss =\n",
    "        # TODO: to add likelihood\n",
    "        # self.log_loss =\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # Return the average MSE loss.\n",
    "        mse_loss = self.mse_loss(logits, target).div_(2)\n",
    "        loss = mse_loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    # Define hyper-parameters.\n",
    "    depth = int(config[\"DnCNN\"][\"depth\"])\n",
    "    n_channels = int(config[\"DnCNN\"][\"n_channels\"])\n",
    "    img_channel = int(config[\"DnCNN\"][\"img_channel\"])\n",
    "    kernel_size = int(config[\"DnCNN\"][\"kernel_size\"])\n",
    "    use_bnorm = config.getboolean(\"DnCNN\", \"use_bnorm\")\n",
    "    epochs = int(config[\"DnCNN\"][\"epoch\"])\n",
    "    batch_size = int(config[\"DnCNN\"][\"batch_size\"])\n",
    "    train_data_dir = config[\"DnCNN\"][\"train_data_dir\"]\n",
    "    test_data_dir = config[\"DnCNN\"][\"test_data_dir\"]\n",
    "    eta_min = float(config[\"DnCNN\"][\"eta_min\"])\n",
    "    eta_max = float(config[\"DnCNN\"][\"eta_max\"])\n",
    "    dose = float(config[\"DnCNN\"][\"dose\"])\n",
    "    model_save_dir = config[\"DnCNN\"][\"model_save_dir\"]\n",
    "\n",
    "    # Save logs to txt file.\n",
    "    log_dir = config[\"DnCNN\"][\"log_dir\"]\n",
    "    log_dir = Path(log_dir) / \"dose{}\".format(str(int(dose * 100)))\n",
    "    log_file = log_dir / \"train_result.txt\"\n",
    "\n",
    "    # Define device.\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initiate a DnCNN instance.\n",
    "    # Load the model to device and set the model to training.\n",
    "    model = DnCNN(depth=depth, n_channels=n_channels,\n",
    "                  img_channel=img_channel,\n",
    "                  use_bnorm=use_bnorm,\n",
    "                  kernel_size=kernel_size)\n",
    "\n",
    "    model = model.to(device)\n",
    "    restore_model(18, model_save_dir, model, train=True)\n",
    "#     model.train()\n",
    "\n",
    "    # Define loss criterion and optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)\n",
    "    criterion = LossFunc(reduction=\"mean\")\n",
    "\n",
    "    # Get a validation test set and corrupt with noise for validation performance.\n",
    "    # For every epoch, use this pre-determined noisy images.\n",
    "    test_file_list = glob.glob(test_data_dir + \"/*.png\")\n",
    "    xs_test = []\n",
    "    # Can't directly convert the xs_test from list to ndarray because some images are 512*512\n",
    "    # while the rest are 256*256.\n",
    "    for i in range(len(test_file_list)):\n",
    "        img = cv2.imread(test_file_list[i], 0)\n",
    "        img = np.array(img, dtype=\"float32\") / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img_noisy, _ = nm(img, eta_min, eta_max, dose, t=100)\n",
    "        xs_test.append((img_noisy, img))\n",
    "\n",
    "    # Train the model.\n",
    "    loss_store = []\n",
    "    epoch_loss_store = []\n",
    "    psnr_store = []\n",
    "    ssim_store = []\n",
    "\n",
    "    psnr_tr_store = []\n",
    "    ssim_tr_store = []\n",
    "    \n",
    "    loss_mse = torch.nn.MSELoss()\n",
    "\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    # load vgg network\n",
    "    vgg = Vgg16().type(dtype)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # For each epoch, generate clean augmented patches from the training directory.\n",
    "        # Convert the data from uint8 to float32 then scale them to make it in [0, 1].\n",
    "        # Then make the patches to be of shape [N, C, H, W],\n",
    "        # where N is the batch size, C is the number of color channels.\n",
    "        # H and W are height and width of image patches.\n",
    "        xs = dg.datagenerator(data_dir=train_data_dir)\n",
    "        xs = xs.astype(\"float32\") / 255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))\n",
    "\n",
    "        train_set = dg.DenoisingDatatset(xs, eta_min, eta_max, dose)\n",
    "        train_loader = DataLoader(dataset=train_set, num_workers=4,\n",
    "                                  drop_last=True, batch_size=batch_size,\n",
    "                                  shuffle=True)  # TODO: if drop_last=True, the dropping in the\n",
    "                                                 # TODO: data_generator is not necessary?\n",
    "\n",
    "        # train_loader_test = next(iter(train_loader))\n",
    "\n",
    "        t_start = timer()\n",
    "        epoch_loss = 0\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            img_batch_read = len(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # We can use labels for both style and content image\n",
    "            \n",
    "                # style image\n",
    "#             style_transform = transforms.Compose([\n",
    "#             normalize_tensor_transform()      # normalize with ImageNet values\n",
    "#             ])\n",
    "            \n",
    "#             labels_t = style_transform(labels)\n",
    "                        \n",
    "#             labels_t = labels.repeat(1, 3, 1, 1)\n",
    "#             outputs_t = outputs.repeat(1, 3, 1, 1)            \n",
    "            \n",
    "            labels_t = torch.zeros(128, 3, 40, 40).cuda()\n",
    "            labels_t[:,1,:,:] = labels.squeeze()\n",
    "            \n",
    "            outputs_t = torch.zeros(128, 3, 40, 40).cuda()\n",
    "            outputs_t[:,1,:,:] = outputs.squeeze()\n",
    "                        \n",
    "            y_c_features = vgg(labels_t)\n",
    "            style_gram = [gram(fmap) for fmap in y_c_features]\n",
    "            \n",
    "            y_hat_features = vgg(outputs_t)\n",
    "            y_hat_gram = [gram(fmap) for fmap in y_hat_features]    \n",
    "            \n",
    "            \n",
    "            # calculate style loss\n",
    "            style_loss = 0.0\n",
    "            for j in range(4):\n",
    "                style_loss += loss_mse(y_hat_gram[j], style_gram[j][:img_batch_read])\n",
    "            style_loss = STYLE_WEIGHT*style_loss\n",
    "            aggregate_style_loss = style_loss\n",
    "\n",
    "            # calculate content loss (h_relu_2_2)\n",
    "            recon = y_c_features[1]      \n",
    "            recon_hat = y_hat_features[1]\n",
    "            content_loss = CONTENT_WEIGHT*loss_mse(recon_hat, recon)\n",
    "            aggregate_content_loss = content_loss\n",
    "            \n",
    "            diff_i = torch.sum(torch.abs(outputs_t[:, :, :, 1:] - outputs_t[:, :, :, :-1]))\n",
    "            diff_j = torch.sum(torch.abs(outputs_t[:, :, 1:, :] - outputs_t[:, :, :-1, :]))\n",
    "            tv_loss = (1e-4)*(diff_i + diff_j)\n",
    "            aggregate_tv_loss = tv_loss\n",
    "            \n",
    "            loss = aggregate_content_loss + aggregate_style_loss + aggregate_tv_loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_store.append(loss.item())\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                print(\"Epoch [{} / {}], step [{} / {}], loss = {:.5f}, lr = {:.6f}, elapsed time = {:.2f}s\".format(\n",
    "                    epoch + 1, epochs, idx, len(train_loader), loss.item(), *scheduler.get_last_lr(), timer()-t_start))\n",
    "\n",
    "        epoch_loss_store.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # At each epoch validate the result.\n",
    "        model = model.eval()\n",
    "\n",
    "        # # Firstly validate on training sets. This takes a long time so I commented.\n",
    "        # tr_psnr = []\n",
    "        # tr_ssim = []\n",
    "        # # t_start = timer()\n",
    "        # with torch.no_grad():\n",
    "        #     for idx, train_data in enumerate(train_loader):\n",
    "        #         inputs, labels = train_data\n",
    "        #         # print(inputs.shape)\n",
    "        #         # inputs = np.expand_dims(inputs, axis=0)\n",
    "        #         # inputs = torch.from_numpy(inputs).to(device)\n",
    "        #         inputs = inputs.to(device)\n",
    "        #         labels = labels.squeeze().numpy()\n",
    "        #\n",
    "        #         outputs = model(inputs)\n",
    "        #         outputs = outputs.squeeze().cpu().detach().numpy()\n",
    "        #\n",
    "        #         tr_psnr.append(peak_signal_noise_ratio(labels, outputs))\n",
    "        #         tr_ssim.append(structural_similarity(outputs, labels))\n",
    "        # psnr_tr_store.append(sum(tr_psnr) / len(tr_psnr))\n",
    "        # ssim_tr_store.append(sum(tr_ssim) / len(tr_ssim))\n",
    "        # # print(\"Elapsed time = {}\".format(timer() - t_start))\n",
    "        #\n",
    "        # print(\"Validation on train set: epoch [{} / {}], aver PSNR = {:.2f}, aver SSIM = {:.4f}\".format(\n",
    "        #     epoch + 1, epochs, psnr_tr_store[-1], ssim_tr_store[-1]))\n",
    "\n",
    "        # Validate on test set\n",
    "        val_psnr = []\n",
    "        val_ssim = []\n",
    "        with torch.no_grad():\n",
    "            for idx, test_data in enumerate(xs_test):\n",
    "                inputs, labels = test_data\n",
    "                inputs = np.expand_dims(inputs, axis=0)\n",
    "                inputs = torch.from_numpy(inputs).to(device)\n",
    "                labels = labels.squeeze()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze().cpu().detach().numpy()\n",
    "\n",
    "                val_psnr.append(peak_signal_noise_ratio(labels, outputs))\n",
    "                val_ssim.append(structural_similarity(outputs, labels))\n",
    "\n",
    "        psnr_store.append(sum(val_psnr) / len(val_psnr))\n",
    "        ssim_store.append(sum(val_ssim) / len(val_ssim))\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(psnr_store)\n",
    "        ax.set_title(\"PSNR\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        fig.show()\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(ssim_store)\n",
    "        ax.set_title(\"SSIM\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        fig.show()\n",
    "\n",
    "        print(\"Validation on test set: epoch [{} / {}], aver PSNR = {:.2f}, aver SSIM = {:.4f}\".format(\n",
    "            epoch + 1, epochs, psnr_store[-1], ssim_store[-1]))\n",
    "\n",
    "        # Set model to train mode again.\n",
    "        model = model.train()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save model\n",
    "        save_model(model, model_save_dir, epoch, dose * 100)\n",
    "\n",
    "        # Save the loss and validation PSNR, SSIM.\n",
    "\n",
    "        if not log_dir.exists():\n",
    "            Path.mkdir(log_dir)\n",
    "        with open(log_file, \"a+\") as fh:\n",
    "            # fh.write(\"{} Epoch [{} / {}], loss = {:.6f}, train PSNR = {:.2f}dB, train SSIM = {:.4f}, \"\n",
    "            #          \"validation PSNR = {:.2f}dB, validation SSIM = {:.4f}\".format(\n",
    "            #          datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),\n",
    "            #          epoch + 1, epochs, epoch_loss_store[-1],\n",
    "            #          psnr_tr_store[-1], ssim_tr_store[-1],\n",
    "            #          psnr_store[-1], ssim_store[-1]))\n",
    "            fh.write(\"{} Epoch [{} / {}], loss = {:.6f}, \"\n",
    "                     \"validation PSNR = {:.2f}dB, validation SSIM = {:.4f}\\n\".format(\n",
    "                     datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),\n",
    "                     epoch + 1, epochs, epoch_loss_store[-1],\n",
    "                     psnr_store[-1], ssim_store[-1]))\n",
    "\n",
    "        # np.savetxt(log_file, np.hstack((epoch + 1, epoch_loss_store[-1], psnr_store[-1], ssim_store[-1])), fmt=\"%.6f\", delimiter=\",  \")\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_store[-len(train_loader):])\n",
    "        ax.set_title(\"Last 1862 losses\")\n",
    "        ax.set_xlabel(\"iteration\")\n",
    "        fig.show()\n",
    "\n",
    "    # print(\"Continue\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the trained model from step 18\n",
      "Training data process finished.\n",
      "Epoch [1 / 30], step [0 / 1862], loss = 3.82666, lr = 0.000050, elapsed time = 1.91s\n",
      "Epoch [1 / 30], step [100 / 1862], loss = 3.63008, lr = 0.000050, elapsed time = 37.70s\n",
      "Epoch [1 / 30], step [200 / 1862], loss = 3.66965, lr = 0.000050, elapsed time = 73.50s\n",
      "Epoch [1 / 30], step [300 / 1862], loss = 3.62165, lr = 0.000050, elapsed time = 109.37s\n",
      "Epoch [1 / 30], step [400 / 1862], loss = 4.00361, lr = 0.000050, elapsed time = 145.26s\n",
      "Epoch [1 / 30], step [500 / 1862], loss = 3.74176, lr = 0.000050, elapsed time = 181.01s\n",
      "Epoch [1 / 30], step [600 / 1862], loss = 3.95030, lr = 0.000050, elapsed time = 216.91s\n",
      "Epoch [1 / 30], step [700 / 1862], loss = 3.59763, lr = 0.000050, elapsed time = 252.19s\n",
      "Epoch [1 / 30], step [800 / 1862], loss = 3.56265, lr = 0.000050, elapsed time = 287.13s\n",
      "Epoch [1 / 30], step [900 / 1862], loss = 3.73924, lr = 0.000050, elapsed time = 322.57s\n",
      "Epoch [1 / 30], step [1000 / 1862], loss = 3.64573, lr = 0.000050, elapsed time = 358.02s\n",
      "Epoch [1 / 30], step [1100 / 1862], loss = 3.37741, lr = 0.000050, elapsed time = 393.31s\n",
      "Epoch [1 / 30], step [1200 / 1862], loss = 3.80776, lr = 0.000050, elapsed time = 428.63s\n",
      "Epoch [1 / 30], step [1300 / 1862], loss = 3.73726, lr = 0.000050, elapsed time = 463.92s\n",
      "Epoch [1 / 30], step [1400 / 1862], loss = 3.52948, lr = 0.000050, elapsed time = 499.03s\n",
      "Epoch [1 / 30], step [1500 / 1862], loss = 3.67483, lr = 0.000050, elapsed time = 534.50s\n",
      "Epoch [1 / 30], step [1600 / 1862], loss = 3.47829, lr = 0.000050, elapsed time = 570.25s\n",
      "Epoch [1 / 30], step [1700 / 1862], loss = 3.71496, lr = 0.000050, elapsed time = 606.06s\n",
      "Epoch [1 / 30], step [1800 / 1862], loss = 3.68781, lr = 0.000050, elapsed time = 641.53s\n",
      "Validation on test set: epoch [1 / 30], aver PSNR = 15.59, aver SSIM = 0.6854\n",
      "Saved model checkpoints 1 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [2 / 30], step [0 / 1862], loss = 3.78947, lr = 0.000050, elapsed time = 1.98s\n",
      "Epoch [2 / 30], step [100 / 1862], loss = 3.52893, lr = 0.000050, elapsed time = 37.40s\n",
      "Epoch [2 / 30], step [200 / 1862], loss = 3.67559, lr = 0.000050, elapsed time = 72.62s\n",
      "Epoch [2 / 30], step [300 / 1862], loss = 3.89167, lr = 0.000050, elapsed time = 107.93s\n",
      "Epoch [2 / 30], step [400 / 1862], loss = 3.63834, lr = 0.000050, elapsed time = 143.11s\n",
      "Epoch [2 / 30], step [500 / 1862], loss = 3.48844, lr = 0.000050, elapsed time = 178.34s\n",
      "Epoch [2 / 30], step [600 / 1862], loss = 3.67432, lr = 0.000050, elapsed time = 213.66s\n",
      "Epoch [2 / 30], step [700 / 1862], loss = 3.82127, lr = 0.000050, elapsed time = 248.93s\n",
      "Epoch [2 / 30], step [800 / 1862], loss = 3.84224, lr = 0.000050, elapsed time = 284.41s\n",
      "Epoch [2 / 30], step [900 / 1862], loss = 3.85727, lr = 0.000050, elapsed time = 319.74s\n",
      "Epoch [2 / 30], step [1000 / 1862], loss = 3.66075, lr = 0.000050, elapsed time = 355.12s\n",
      "Epoch [2 / 30], step [1100 / 1862], loss = 3.55861, lr = 0.000050, elapsed time = 390.59s\n",
      "Epoch [2 / 30], step [1200 / 1862], loss = 3.94693, lr = 0.000050, elapsed time = 426.04s\n",
      "Epoch [2 / 30], step [1300 / 1862], loss = 3.46513, lr = 0.000050, elapsed time = 461.41s\n",
      "Epoch [2 / 30], step [1400 / 1862], loss = 3.32161, lr = 0.000050, elapsed time = 496.67s\n",
      "Epoch [2 / 30], step [1500 / 1862], loss = 3.77991, lr = 0.000050, elapsed time = 532.11s\n",
      "Epoch [2 / 30], step [1600 / 1862], loss = 4.43800, lr = 0.000050, elapsed time = 567.50s\n",
      "Epoch [2 / 30], step [1700 / 1862], loss = 4.14855, lr = 0.000050, elapsed time = 602.88s\n",
      "Epoch [2 / 30], step [1800 / 1862], loss = 3.59631, lr = 0.000050, elapsed time = 638.31s\n",
      "Validation on test set: epoch [2 / 30], aver PSNR = 16.59, aver SSIM = 0.7139\n",
      "Saved model checkpoints 2 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [3 / 30], step [0 / 1862], loss = 3.84917, lr = 0.000050, elapsed time = 1.94s\n",
      "Epoch [3 / 30], step [100 / 1862], loss = 3.43290, lr = 0.000050, elapsed time = 37.05s\n",
      "Epoch [3 / 30], step [200 / 1862], loss = 3.52773, lr = 0.000050, elapsed time = 72.24s\n",
      "Epoch [3 / 30], step [300 / 1862], loss = 3.72927, lr = 0.000050, elapsed time = 107.37s\n",
      "Epoch [3 / 30], step [400 / 1862], loss = 3.67468, lr = 0.000050, elapsed time = 142.65s\n",
      "Epoch [3 / 30], step [500 / 1862], loss = 3.62812, lr = 0.000050, elapsed time = 177.99s\n",
      "Epoch [3 / 30], step [600 / 1862], loss = 3.67302, lr = 0.000050, elapsed time = 213.37s\n",
      "Epoch [3 / 30], step [700 / 1862], loss = 3.82636, lr = 0.000050, elapsed time = 248.80s\n",
      "Epoch [3 / 30], step [800 / 1862], loss = 3.85471, lr = 0.000050, elapsed time = 284.07s\n",
      "Epoch [3 / 30], step [900 / 1862], loss = 3.76602, lr = 0.000050, elapsed time = 319.36s\n",
      "Epoch [3 / 30], step [1000 / 1862], loss = 3.48064, lr = 0.000050, elapsed time = 354.50s\n",
      "Epoch [3 / 30], step [1100 / 1862], loss = 3.72322, lr = 0.000050, elapsed time = 389.91s\n",
      "Epoch [3 / 30], step [1200 / 1862], loss = 3.52167, lr = 0.000050, elapsed time = 425.24s\n",
      "Epoch [3 / 30], step [1300 / 1862], loss = 3.52477, lr = 0.000050, elapsed time = 460.59s\n",
      "Epoch [3 / 30], step [1400 / 1862], loss = 3.35027, lr = 0.000050, elapsed time = 495.90s\n",
      "Epoch [3 / 30], step [1500 / 1862], loss = 3.55026, lr = 0.000050, elapsed time = 531.21s\n",
      "Epoch [3 / 30], step [1600 / 1862], loss = 3.50056, lr = 0.000050, elapsed time = 566.46s\n",
      "Epoch [3 / 30], step [1700 / 1862], loss = 3.90777, lr = 0.000050, elapsed time = 601.72s\n",
      "Epoch [3 / 30], step [1800 / 1862], loss = 3.66625, lr = 0.000050, elapsed time = 636.83s\n",
      "Validation on test set: epoch [3 / 30], aver PSNR = 16.17, aver SSIM = 0.6872\n",
      "Saved model checkpoints 3 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [4 / 30], step [0 / 1862], loss = 3.84176, lr = 0.000050, elapsed time = 1.99s\n",
      "Epoch [4 / 30], step [100 / 1862], loss = 3.63095, lr = 0.000050, elapsed time = 37.85s\n",
      "Epoch [4 / 30], step [200 / 1862], loss = 4.16715, lr = 0.000050, elapsed time = 73.32s\n",
      "Epoch [4 / 30], step [300 / 1862], loss = 3.58070, lr = 0.000050, elapsed time = 109.16s\n",
      "Epoch [4 / 30], step [400 / 1862], loss = 3.83520, lr = 0.000050, elapsed time = 144.49s\n",
      "Epoch [4 / 30], step [500 / 1862], loss = 4.14558, lr = 0.000050, elapsed time = 179.78s\n",
      "Epoch [4 / 30], step [600 / 1862], loss = 3.85997, lr = 0.000050, elapsed time = 215.02s\n",
      "Epoch [4 / 30], step [700 / 1862], loss = 3.67686, lr = 0.000050, elapsed time = 250.26s\n",
      "Epoch [4 / 30], step [800 / 1862], loss = 3.66071, lr = 0.000050, elapsed time = 285.54s\n",
      "Epoch [4 / 30], step [900 / 1862], loss = 3.80099, lr = 0.000050, elapsed time = 320.89s\n",
      "Epoch [4 / 30], step [1000 / 1862], loss = 4.24763, lr = 0.000050, elapsed time = 356.26s\n",
      "Epoch [4 / 30], step [1100 / 1862], loss = 3.58208, lr = 0.000050, elapsed time = 391.51s\n",
      "Epoch [4 / 30], step [1200 / 1862], loss = 3.41565, lr = 0.000050, elapsed time = 427.06s\n",
      "Epoch [4 / 30], step [1300 / 1862], loss = 3.86733, lr = 0.000050, elapsed time = 462.69s\n",
      "Epoch [4 / 30], step [1400 / 1862], loss = 3.29364, lr = 0.000050, elapsed time = 498.07s\n",
      "Epoch [4 / 30], step [1500 / 1862], loss = 3.78754, lr = 0.000050, elapsed time = 533.68s\n",
      "Epoch [4 / 30], step [1600 / 1862], loss = 4.07393, lr = 0.000050, elapsed time = 569.12s\n",
      "Epoch [4 / 30], step [1700 / 1862], loss = 3.74158, lr = 0.000050, elapsed time = 604.22s\n",
      "Epoch [4 / 30], step [1800 / 1862], loss = 3.44562, lr = 0.000050, elapsed time = 639.70s\n",
      "Validation on test set: epoch [4 / 30], aver PSNR = 16.53, aver SSIM = 0.7094\n",
      "Saved model checkpoints 4 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [5 / 30], step [0 / 1862], loss = 3.89694, lr = 0.000050, elapsed time = 1.95s\n",
      "Epoch [5 / 30], step [100 / 1862], loss = 3.54987, lr = 0.000050, elapsed time = 37.28s\n",
      "Epoch [5 / 30], step [200 / 1862], loss = 3.88573, lr = 0.000050, elapsed time = 72.80s\n",
      "Epoch [5 / 30], step [300 / 1862], loss = 3.78357, lr = 0.000050, elapsed time = 108.14s\n",
      "Epoch [5 / 30], step [400 / 1862], loss = 4.61637, lr = 0.000050, elapsed time = 143.30s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 30], step [500 / 1862], loss = 3.44763, lr = 0.000050, elapsed time = 178.66s\n",
      "Epoch [5 / 30], step [600 / 1862], loss = 4.01834, lr = 0.000050, elapsed time = 213.92s\n",
      "Epoch [5 / 30], step [700 / 1862], loss = 3.83434, lr = 0.000050, elapsed time = 248.45s\n",
      "Epoch [5 / 30], step [800 / 1862], loss = 3.49231, lr = 0.000050, elapsed time = 283.75s\n",
      "Epoch [5 / 30], step [900 / 1862], loss = 3.98067, lr = 0.000050, elapsed time = 319.11s\n",
      "Epoch [5 / 30], step [1000 / 1862], loss = 3.82155, lr = 0.000050, elapsed time = 354.43s\n",
      "Epoch [5 / 30], step [1100 / 1862], loss = 3.83323, lr = 0.000050, elapsed time = 390.05s\n",
      "Epoch [5 / 30], step [1200 / 1862], loss = 3.42923, lr = 0.000050, elapsed time = 425.24s\n",
      "Epoch [5 / 30], step [1300 / 1862], loss = 3.52505, lr = 0.000050, elapsed time = 460.56s\n",
      "Epoch [5 / 30], step [1400 / 1862], loss = 3.98573, lr = 0.000050, elapsed time = 495.87s\n",
      "Epoch [5 / 30], step [1500 / 1862], loss = 3.64190, lr = 0.000050, elapsed time = 531.10s\n",
      "Epoch [5 / 30], step [1600 / 1862], loss = 3.58425, lr = 0.000050, elapsed time = 566.54s\n",
      "Epoch [5 / 30], step [1700 / 1862], loss = 4.19628, lr = 0.000050, elapsed time = 602.06s\n",
      "Epoch [5 / 30], step [1800 / 1862], loss = 3.81958, lr = 0.000050, elapsed time = 637.36s\n",
      "Validation on test set: epoch [5 / 30], aver PSNR = 17.04, aver SSIM = 0.7097\n",
      "Saved model checkpoints 5 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [6 / 30], step [0 / 1862], loss = 3.64642, lr = 0.000050, elapsed time = 1.95s\n",
      "Epoch [6 / 30], step [100 / 1862], loss = 3.45518, lr = 0.000050, elapsed time = 37.27s\n",
      "Epoch [6 / 30], step [200 / 1862], loss = 3.86112, lr = 0.000050, elapsed time = 72.48s\n",
      "Epoch [6 / 30], step [300 / 1862], loss = 3.39397, lr = 0.000050, elapsed time = 108.10s\n",
      "Epoch [6 / 30], step [400 / 1862], loss = 3.91078, lr = 0.000050, elapsed time = 143.92s\n",
      "Epoch [6 / 30], step [500 / 1862], loss = 3.73333, lr = 0.000050, elapsed time = 179.70s\n",
      "Epoch [6 / 30], step [600 / 1862], loss = 4.10286, lr = 0.000050, elapsed time = 215.37s\n",
      "Epoch [6 / 30], step [700 / 1862], loss = 3.92284, lr = 0.000050, elapsed time = 250.86s\n",
      "Epoch [6 / 30], step [800 / 1862], loss = 3.56361, lr = 0.000050, elapsed time = 286.45s\n",
      "Epoch [6 / 30], step [900 / 1862], loss = 3.81808, lr = 0.000050, elapsed time = 321.92s\n",
      "Epoch [6 / 30], step [1000 / 1862], loss = 4.15581, lr = 0.000050, elapsed time = 357.33s\n",
      "Epoch [6 / 30], step [1100 / 1862], loss = 4.23063, lr = 0.000050, elapsed time = 393.01s\n",
      "Epoch [6 / 30], step [1200 / 1862], loss = 3.61437, lr = 0.000050, elapsed time = 428.57s\n",
      "Epoch [6 / 30], step [1300 / 1862], loss = 3.62191, lr = 0.000050, elapsed time = 463.92s\n",
      "Epoch [6 / 30], step [1400 / 1862], loss = 3.64699, lr = 0.000050, elapsed time = 499.22s\n",
      "Epoch [6 / 30], step [1500 / 1862], loss = 3.82678, lr = 0.000050, elapsed time = 534.58s\n",
      "Epoch [6 / 30], step [1600 / 1862], loss = 3.42145, lr = 0.000050, elapsed time = 570.02s\n",
      "Epoch [6 / 30], step [1700 / 1862], loss = 3.53320, lr = 0.000050, elapsed time = 605.38s\n",
      "Epoch [6 / 30], step [1800 / 1862], loss = 3.65272, lr = 0.000050, elapsed time = 640.71s\n",
      "Validation on test set: epoch [6 / 30], aver PSNR = 15.58, aver SSIM = 0.6881\n",
      "Saved model checkpoints 6 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [7 / 30], step [0 / 1862], loss = 3.65976, lr = 0.000050, elapsed time = 1.99s\n",
      "Epoch [7 / 30], step [100 / 1862], loss = 3.64965, lr = 0.000050, elapsed time = 37.36s\n",
      "Epoch [7 / 30], step [200 / 1862], loss = 3.91935, lr = 0.000050, elapsed time = 72.69s\n",
      "Epoch [7 / 30], step [300 / 1862], loss = 3.56719, lr = 0.000050, elapsed time = 107.94s\n",
      "Epoch [7 / 30], step [400 / 1862], loss = 3.64294, lr = 0.000050, elapsed time = 143.25s\n",
      "Epoch [7 / 30], step [500 / 1862], loss = 3.45621, lr = 0.000050, elapsed time = 178.42s\n",
      "Epoch [7 / 30], step [600 / 1862], loss = 3.46434, lr = 0.000050, elapsed time = 213.62s\n",
      "Epoch [7 / 30], step [700 / 1862], loss = 3.65723, lr = 0.000050, elapsed time = 248.67s\n",
      "Epoch [7 / 30], step [800 / 1862], loss = 3.46767, lr = 0.000050, elapsed time = 283.61s\n",
      "Epoch [7 / 30], step [900 / 1862], loss = 3.43118, lr = 0.000050, elapsed time = 318.71s\n",
      "Epoch [7 / 30], step [1000 / 1862], loss = 3.33577, lr = 0.000050, elapsed time = 354.03s\n",
      "Epoch [7 / 30], step [1100 / 1862], loss = 3.65916, lr = 0.000050, elapsed time = 389.27s\n",
      "Epoch [7 / 30], step [1200 / 1862], loss = 3.68448, lr = 0.000050, elapsed time = 424.47s\n",
      "Epoch [7 / 30], step [1300 / 1862], loss = 3.91439, lr = 0.000050, elapsed time = 459.68s\n",
      "Epoch [7 / 30], step [1400 / 1862], loss = 3.96416, lr = 0.000050, elapsed time = 495.06s\n",
      "Epoch [7 / 30], step [1500 / 1862], loss = 3.92198, lr = 0.000050, elapsed time = 530.43s\n",
      "Epoch [7 / 30], step [1600 / 1862], loss = 3.77266, lr = 0.000050, elapsed time = 565.77s\n",
      "Epoch [7 / 30], step [1700 / 1862], loss = 3.98169, lr = 0.000050, elapsed time = 601.21s\n",
      "Epoch [7 / 30], step [1800 / 1862], loss = 4.03036, lr = 0.000050, elapsed time = 636.64s\n",
      "Validation on test set: epoch [7 / 30], aver PSNR = 15.95, aver SSIM = 0.6961\n",
      "Saved model checkpoints 7 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/ipykernel_launcher.py:332: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data process finished.\n",
      "Epoch [8 / 30], step [0 / 1862], loss = 4.02661, lr = 0.000050, elapsed time = 1.97s\n",
      "Epoch [8 / 30], step [100 / 1862], loss = 3.91728, lr = 0.000050, elapsed time = 37.31s\n",
      "Epoch [8 / 30], step [200 / 1862], loss = 3.56886, lr = 0.000050, elapsed time = 72.79s\n",
      "Epoch [8 / 30], step [300 / 1862], loss = 3.43161, lr = 0.000050, elapsed time = 108.07s\n",
      "Epoch [8 / 30], step [400 / 1862], loss = 4.05611, lr = 0.000050, elapsed time = 143.06s\n",
      "Epoch [8 / 30], step [500 / 1862], loss = 3.71875, lr = 0.000050, elapsed time = 178.23s\n",
      "Epoch [8 / 30], step [600 / 1862], loss = 4.24191, lr = 0.000050, elapsed time = 213.45s\n",
      "Epoch [8 / 30], step [700 / 1862], loss = 3.68540, lr = 0.000050, elapsed time = 248.66s\n",
      "Epoch [8 / 30], step [800 / 1862], loss = 3.79869, lr = 0.000050, elapsed time = 283.84s\n",
      "Epoch [8 / 30], step [900 / 1862], loss = 3.61723, lr = 0.000050, elapsed time = 319.10s\n",
      "Epoch [8 / 30], step [1000 / 1862], loss = 3.82956, lr = 0.000050, elapsed time = 354.36s\n",
      "Epoch [8 / 30], step [1100 / 1862], loss = 3.62315, lr = 0.000050, elapsed time = 389.69s\n",
      "Epoch [8 / 30], step [1200 / 1862], loss = 3.83745, lr = 0.000050, elapsed time = 424.96s\n",
      "Epoch [8 / 30], step [1300 / 1862], loss = 3.89057, lr = 0.000050, elapsed time = 460.07s\n",
      "Epoch [8 / 30], step [1400 / 1862], loss = 3.56656, lr = 0.000050, elapsed time = 495.27s\n",
      "Epoch [8 / 30], step [1500 / 1862], loss = 4.03148, lr = 0.000050, elapsed time = 530.49s\n",
      "Epoch [8 / 30], step [1600 / 1862], loss = 3.61165, lr = 0.000050, elapsed time = 565.74s\n",
      "Epoch [8 / 30], step [1700 / 1862], loss = 3.85158, lr = 0.000050, elapsed time = 601.08s\n",
      "Epoch [8 / 30], step [1800 / 1862], loss = 3.51282, lr = 0.000050, elapsed time = 636.32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/ipykernel_launcher.py:290: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "/share/pkg.7/python3/3.7.7/install/lib/python3.7/site-packages/ipykernel_launcher.py:296: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation on test set: epoch [8 / 30], aver PSNR = 16.49, aver SSIM = 0.7007\n",
      "Saved model checkpoints 8 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [9 / 30], step [0 / 1862], loss = 3.73983, lr = 0.000050, elapsed time = 1.98s\n",
      "Epoch [9 / 30], step [100 / 1862], loss = 3.38970, lr = 0.000050, elapsed time = 37.20s\n",
      "Epoch [9 / 30], step [200 / 1862], loss = 3.48867, lr = 0.000050, elapsed time = 72.65s\n",
      "Epoch [9 / 30], step [300 / 1862], loss = 3.70417, lr = 0.000050, elapsed time = 108.12s\n",
      "Epoch [9 / 30], step [400 / 1862], loss = 3.69824, lr = 0.000050, elapsed time = 143.36s\n",
      "Epoch [9 / 30], step [500 / 1862], loss = 3.43960, lr = 0.000050, elapsed time = 178.49s\n",
      "Epoch [9 / 30], step [600 / 1862], loss = 3.70229, lr = 0.000050, elapsed time = 213.57s\n",
      "Epoch [9 / 30], step [700 / 1862], loss = 3.63471, lr = 0.000050, elapsed time = 248.86s\n",
      "Epoch [9 / 30], step [800 / 1862], loss = 3.50209, lr = 0.000050, elapsed time = 284.29s\n",
      "Epoch [9 / 30], step [900 / 1862], loss = 3.62404, lr = 0.000050, elapsed time = 319.73s\n",
      "Epoch [9 / 30], step [1000 / 1862], loss = 3.54163, lr = 0.000050, elapsed time = 355.24s\n",
      "Epoch [9 / 30], step [1100 / 1862], loss = 3.24396, lr = 0.000050, elapsed time = 390.44s\n",
      "Epoch [9 / 30], step [1200 / 1862], loss = 3.83687, lr = 0.000050, elapsed time = 425.71s\n",
      "Epoch [9 / 30], step [1300 / 1862], loss = 3.61991, lr = 0.000050, elapsed time = 460.98s\n",
      "Epoch [9 / 30], step [1400 / 1862], loss = 3.56488, lr = 0.000050, elapsed time = 496.21s\n",
      "Epoch [9 / 30], step [1500 / 1862], loss = 3.47123, lr = 0.000050, elapsed time = 531.43s\n",
      "Epoch [9 / 30], step [1600 / 1862], loss = 3.56528, lr = 0.000050, elapsed time = 566.75s\n",
      "Epoch [9 / 30], step [1700 / 1862], loss = 3.85415, lr = 0.000050, elapsed time = 601.90s\n",
      "Epoch [9 / 30], step [1800 / 1862], loss = 3.43072, lr = 0.000050, elapsed time = 636.76s\n",
      "Validation on test set: epoch [9 / 30], aver PSNR = 16.36, aver SSIM = 0.7036\n",
      "Saved model checkpoints 9 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [10 / 30], step [0 / 1862], loss = 4.08053, lr = 0.000050, elapsed time = 1.98s\n",
      "Epoch [10 / 30], step [100 / 1862], loss = 3.49778, lr = 0.000050, elapsed time = 37.57s\n",
      "Epoch [10 / 30], step [200 / 1862], loss = 3.39460, lr = 0.000050, elapsed time = 72.96s\n",
      "Epoch [10 / 30], step [300 / 1862], loss = 3.49505, lr = 0.000050, elapsed time = 108.12s\n",
      "Epoch [10 / 30], step [400 / 1862], loss = 3.65590, lr = 0.000050, elapsed time = 143.38s\n",
      "Epoch [10 / 30], step [500 / 1862], loss = 3.89214, lr = 0.000050, elapsed time = 178.68s\n",
      "Epoch [10 / 30], step [600 / 1862], loss = 3.85556, lr = 0.000050, elapsed time = 214.04s\n",
      "Epoch [10 / 30], step [700 / 1862], loss = 3.81857, lr = 0.000050, elapsed time = 249.46s\n",
      "Epoch [10 / 30], step [800 / 1862], loss = 3.82364, lr = 0.000050, elapsed time = 284.91s\n",
      "Epoch [10 / 30], step [900 / 1862], loss = 3.92007, lr = 0.000050, elapsed time = 320.34s\n",
      "Epoch [10 / 30], step [1000 / 1862], loss = 3.68942, lr = 0.000050, elapsed time = 355.73s\n",
      "Epoch [10 / 30], step [1100 / 1862], loss = 3.65151, lr = 0.000050, elapsed time = 391.09s\n",
      "Epoch [10 / 30], step [1200 / 1862], loss = 3.51552, lr = 0.000050, elapsed time = 426.58s\n",
      "Epoch [10 / 30], step [1300 / 1862], loss = 3.76864, lr = 0.000050, elapsed time = 461.87s\n",
      "Epoch [10 / 30], step [1400 / 1862], loss = 3.76708, lr = 0.000050, elapsed time = 497.33s\n",
      "Epoch [10 / 30], step [1500 / 1862], loss = 3.44544, lr = 0.000050, elapsed time = 532.84s\n",
      "Epoch [10 / 30], step [1600 / 1862], loss = 3.94539, lr = 0.000050, elapsed time = 567.93s\n",
      "Epoch [10 / 30], step [1700 / 1862], loss = 3.94730, lr = 0.000050, elapsed time = 603.52s\n",
      "Epoch [10 / 30], step [1800 / 1862], loss = 4.02706, lr = 0.000050, elapsed time = 638.98s\n",
      "Validation on test set: epoch [10 / 30], aver PSNR = 16.34, aver SSIM = 0.7002\n",
      "Saved model checkpoints 10 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_last/dose20/dose20\n",
      "Training data process finished.\n",
      "Epoch [11 / 30], step [0 / 1862], loss = 3.85968, lr = 0.000050, elapsed time = 1.98s\n",
      "Epoch [11 / 30], step [100 / 1862], loss = 3.82709, lr = 0.000050, elapsed time = 37.59s\n",
      "Epoch [11 / 30], step [200 / 1862], loss = 3.71700, lr = 0.000050, elapsed time = 72.85s\n",
      "Epoch [11 / 30], step [300 / 1862], loss = 3.37324, lr = 0.000050, elapsed time = 108.07s\n",
      "Epoch [11 / 30], step [400 / 1862], loss = 3.27003, lr = 0.000050, elapsed time = 143.18s\n",
      "Epoch [11 / 30], step [500 / 1862], loss = 3.87375, lr = 0.000050, elapsed time = 178.49s\n",
      "Epoch [11 / 30], step [600 / 1862], loss = 3.63995, lr = 0.000050, elapsed time = 213.91s\n",
      "Epoch [11 / 30], step [700 / 1862], loss = 3.68628, lr = 0.000050, elapsed time = 249.15s\n",
      "Epoch [11 / 30], step [800 / 1862], loss = 3.52729, lr = 0.000050, elapsed time = 284.49s\n",
      "Epoch [11 / 30], step [900 / 1862], loss = 3.95186, lr = 0.000050, elapsed time = 319.81s\n",
      "Epoch [11 / 30], step [1000 / 1862], loss = 3.76151, lr = 0.000050, elapsed time = 355.14s\n",
      "Epoch [11 / 30], step [1100 / 1862], loss = 4.00652, lr = 0.000050, elapsed time = 390.45s\n",
      "Epoch [11 / 30], step [1200 / 1862], loss = 3.74082, lr = 0.000050, elapsed time = 425.45s\n",
      "Epoch [11 / 30], step [1300 / 1862], loss = 3.74640, lr = 0.000050, elapsed time = 460.55s\n",
      "Epoch [11 / 30], step [1400 / 1862], loss = 3.97484, lr = 0.000050, elapsed time = 495.78s\n",
      "Epoch [11 / 30], step [1500 / 1862], loss = 3.79975, lr = 0.000050, elapsed time = 530.95s\n",
      "Epoch [11 / 30], step [1600 / 1862], loss = 3.81392, lr = 0.000050, elapsed time = 566.15s\n",
      "Epoch [11 / 30], step [1700 / 1862], loss = 3.29056, lr = 0.000050, elapsed time = 601.23s\n",
      "Epoch [11 / 30], step [1800 / 1862], loss = 3.62601, lr = 0.000050, elapsed time = 636.62s\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    config = configparser.ConfigParser()\n",
    "\n",
    "    config.read(\"/projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/cfg_tv.ini\")\n",
    "\n",
    "    train_model(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
