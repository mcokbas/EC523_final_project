{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from pathlib import Path\n",
    "from model import DnCNN\n",
    "import data_generator as dg\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from timeit import default_timer as timer\n",
    "import cv2\n",
    "from skimage.metrics import peak_signal_noise_ratio\n",
    "from skimage.metrics import structural_similarity\n",
    "import glob\n",
    "from noise_model import poissonpoissonnoise as nm\n",
    "import datetime\n",
    "from vgg import Vgg16\n",
    "from torchvision import transforms\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "STYLE_WEIGHT = 1e5\n",
    "CONTENT_WEIGHT = 1e0\n",
    "\n",
    "# manualSeed = 999\n",
    "# # manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "# print(\"Random Seed: \", manualSeed)\n",
    "# random.seed(manualSeed)\n",
    "# np.random.seed(manualSeed)\n",
    "# torch.manual_seed(manualSeed)\n",
    "def gram(x):\n",
    "    (bs, ch, h, w) = x.size()\n",
    "    f = x.view(bs, ch, w*h)\n",
    "    f_T = f.transpose(1, 2)\n",
    "    G = f.bmm(f_T) / (ch * h * w)\n",
    "    return G\n",
    "\n",
    "def _tensor_transform():\n",
    "    return transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def save_model(net: nn.Module, model_save_dir, step, dose_total):\n",
    "    \"\"\"\n",
    "    Save the trained model.\n",
    "\n",
    "    Args:\n",
    "        net: trained model.\n",
    "        model_save_dir: saved model directory.\n",
    "        step: checkpoint.\n",
    "    \"\"\"\n",
    "    model_save_dir = Path(model_save_dir) / \"dose{}\".format(str(int(dose_total)))\n",
    "    if not Path(model_save_dir).exists():\n",
    "        Path.mkdir(model_save_dir)\n",
    "    model_path = Path(model_save_dir) / \"{}.pth\".format(step + 1)\n",
    "\n",
    "    torch.save(net.state_dict(), model_path)\n",
    "\n",
    "    print(\"Saved model checkpoints {} into {}\".format(step + 1, model_save_dir))\n",
    "\n",
    "\n",
    "def restore_model(resume_iters, model_save_dir, net: nn.Module, train=True):\n",
    "    \"\"\"\n",
    "    Restore the trained model.\n",
    "\n",
    "    Args:\n",
    "        resume_iters: the iteration to be loaded.\n",
    "        model_save_dir: the directory for saving the model.\n",
    "        net: the model instance to be loaded.\n",
    "        train: if True, then the model is set to training;\n",
    "               else set it to test.\n",
    "\n",
    "    Returns:\n",
    "        net: loaded model instance.\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Loading the trained model from step {}\".format(resume_iters))\n",
    "    model_path = Path(model_save_dir) / \"{}.pth\".format(resume_iters)\n",
    "\n",
    "    # Restore the model.\n",
    "    net.load_state_dict(torch.load(model_path))\n",
    "\n",
    "    if train:\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "class LossFunc(nn.Module):\n",
    "    def __init__(self, reduction=\"sum\"):\n",
    "        super(LossFunc, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.mse_loss = nn.MSELoss(reduction=reduction)\n",
    "        # TODO: to add TV loss.\n",
    "        # self.tv_loss =\n",
    "        # TODO: to add likelihood\n",
    "        # self.log_loss =\n",
    "\n",
    "    def forward(self, logits, target):\n",
    "        # Return the average MSE loss.\n",
    "        mse_loss = self.mse_loss(logits, target).div_(2)\n",
    "        loss = mse_loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "def train_model(config):\n",
    "    # Define hyper-parameters.\n",
    "    depth = int(config[\"DnCNN\"][\"depth\"])\n",
    "    n_channels = int(config[\"DnCNN\"][\"n_channels\"])\n",
    "    img_channel = int(config[\"DnCNN\"][\"img_channel\"])\n",
    "    kernel_size = int(config[\"DnCNN\"][\"kernel_size\"])\n",
    "    use_bnorm = config.getboolean(\"DnCNN\", \"use_bnorm\")\n",
    "    epochs = int(config[\"DnCNN\"][\"epoch\"])\n",
    "    batch_size = int(config[\"DnCNN\"][\"batch_size\"])\n",
    "    train_data_dir = config[\"DnCNN\"][\"train_data_dir\"]\n",
    "    test_data_dir = config[\"DnCNN\"][\"test_data_dir\"]\n",
    "    eta_min = float(config[\"DnCNN\"][\"eta_min\"])\n",
    "    eta_max = float(config[\"DnCNN\"][\"eta_max\"])\n",
    "    dose = float(config[\"DnCNN\"][\"dose\"])\n",
    "    model_save_dir = config[\"DnCNN\"][\"model_save_dir\"]\n",
    "\n",
    "    # Save logs to txt file.\n",
    "    log_dir = config[\"DnCNN\"][\"log_dir\"]\n",
    "    log_dir = Path(log_dir) / \"dose{}\".format(str(int(dose * 100)))\n",
    "    log_file = log_dir / \"train_result.txt\"\n",
    "\n",
    "    # Define device.\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Initiate a DnCNN instance.\n",
    "    # Load the model to device and set the model to training.\n",
    "    model = DnCNN(depth=depth, n_channels=n_channels,\n",
    "                  img_channel=img_channel,\n",
    "                  use_bnorm=use_bnorm,\n",
    "                  kernel_size=kernel_size)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # Define loss criterion and optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)\n",
    "    criterion = LossFunc(reduction=\"mean\")\n",
    "\n",
    "    # Get a validation test set and corrupt with noise for validation performance.\n",
    "    # For every epoch, use this pre-determined noisy images.\n",
    "    test_file_list = glob.glob(test_data_dir + \"/*.png\")\n",
    "    xs_test = []\n",
    "    # Can't directly convert the xs_test from list to ndarray because some images are 512*512\n",
    "    # while the rest are 256*256.\n",
    "    for i in range(len(test_file_list)):\n",
    "        img = cv2.imread(test_file_list[i], 0)\n",
    "        img = np.array(img, dtype=\"float32\") / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img_noisy, _ = nm(img, eta_min, eta_max, dose, t=100)\n",
    "        xs_test.append((img_noisy, img))\n",
    "\n",
    "    # Train the model.\n",
    "    loss_store = []\n",
    "    epoch_loss_store = []\n",
    "    psnr_store = []\n",
    "    ssim_store = []\n",
    "\n",
    "    psnr_tr_store = []\n",
    "    ssim_tr_store = []\n",
    "    \n",
    "    loss_mse = torch.nn.MSELoss()\n",
    "\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    # load vgg network\n",
    "    vgg = Vgg16().type(dtype)\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # For each epoch, generate clean augmented patches from the training directory.\n",
    "        # Convert the data from uint8 to float32 then scale them to make it in [0, 1].\n",
    "        # Then make the patches to be of shape [N, C, H, W],\n",
    "        # where N is the batch size, C is the number of color channels.\n",
    "        # H and W are height and width of image patches.\n",
    "        xs = dg.datagenerator(data_dir=train_data_dir)\n",
    "        xs = xs.astype(\"float32\") / 255.0\n",
    "        xs = torch.from_numpy(xs.transpose((0, 3, 1, 2)))\n",
    "\n",
    "        train_set = dg.DenoisingDatatset(xs, eta_min, eta_max, dose)\n",
    "        train_loader = DataLoader(dataset=train_set, num_workers=4,\n",
    "                                  drop_last=True, batch_size=batch_size,\n",
    "                                  shuffle=True)  # TODO: if drop_last=True, the dropping in the\n",
    "                                                 # TODO: data_generator is not necessary?\n",
    "\n",
    "        # train_loader_test = next(iter(train_loader))\n",
    "\n",
    "        t_start = timer()\n",
    "        epoch_loss = 0\n",
    "        for idx, data in enumerate(train_loader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            img_batch_read = len(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # We can use labels for both style and content image\n",
    "            \n",
    "                # style image\n",
    "#             style_transform = transforms.Compose([\n",
    "#             normalize_tensor_transform()      # normalize with ImageNet values\n",
    "#             ])\n",
    "            \n",
    "#             labels_t = style_transform(labels)\n",
    "                        \n",
    "#             labels_t = labels.repeat(1, 3, 1, 1)\n",
    "#             outputs_t = outputs.repeat(1, 3, 1, 1)            \n",
    "            \n",
    "    \n",
    "            labels_t = torch.zeros(128, 3, 40, 40).cuda()\n",
    "            labels_t[:,1,:,:] = labels.squeeze()\n",
    "            \n",
    "            outputs_t = torch.zeros(128, 3, 40, 40).cuda()\n",
    "            outputs_t[:,1,:,:] = outputs.squeeze()\n",
    "            \n",
    "            y_c_features = vgg(labels_t)\n",
    "#             style_gram = [gram(fmap) for fmap in y_c_features]\n",
    "            \n",
    "            y_hat_features = vgg(outputs_t)\n",
    "#             y_hat_gram = [gram(fmap) for fmap in y_hat_features]            \n",
    "            \n",
    "            # calculate style loss\n",
    "#             style_loss = 0.0\n",
    "#             for j in range(4):\n",
    "#                 style_loss += loss_mse(y_hat_gram[j], style_gram[j][:img_batch_read])\n",
    "#             style_loss = STYLE_WEIGHT*style_loss\n",
    "#             aggregate_style_loss = style_loss\n",
    "\n",
    "            # calculate content loss (h_relu_2_2)\n",
    "            recon = y_c_features[1]      \n",
    "            recon_hat = y_hat_features[1]\n",
    "            content_loss = CONTENT_WEIGHT*loss_mse(recon_hat, recon)\n",
    "            aggregate_content_loss = content_loss\n",
    "            \n",
    "            loss = aggregate_content_loss\n",
    "#             loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss_store.append(loss.item())\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if idx % 100 == 0:\n",
    "                print(\"Epoch [{} / {}], step [{} / {}], loss = {:.5f}, lr = {:.6f}, elapsed time = {:.2f}s\".format(\n",
    "                    epoch + 1, epochs, idx, len(train_loader), loss.item(), *scheduler.get_last_lr(), timer()-t_start))\n",
    "\n",
    "        epoch_loss_store.append(epoch_loss / len(train_loader))\n",
    "\n",
    "        # At each epoch validate the result.\n",
    "        model = model.eval()\n",
    "\n",
    "        # # Firstly validate on training sets. This takes a long time so I commented.\n",
    "        # tr_psnr = []\n",
    "        # tr_ssim = []\n",
    "        # # t_start = timer()\n",
    "        # with torch.no_grad():\n",
    "        #     for idx, train_data in enumerate(train_loader):\n",
    "        #         inputs, labels = train_data\n",
    "        #         # print(inputs.shape)\n",
    "        #         # inputs = np.expand_dims(inputs, axis=0)\n",
    "        #         # inputs = torch.from_numpy(inputs).to(device)\n",
    "        #         inputs = inputs.to(device)\n",
    "        #         labels = labels.squeeze().numpy()\n",
    "        #\n",
    "        #         outputs = model(inputs)\n",
    "        #         outputs = outputs.squeeze().cpu().detach().numpy()\n",
    "        #\n",
    "        #         tr_psnr.append(peak_signal_noise_ratio(labels, outputs))\n",
    "        #         tr_ssim.append(structural_similarity(outputs, labels))\n",
    "        # psnr_tr_store.append(sum(tr_psnr) / len(tr_psnr))\n",
    "        # ssim_tr_store.append(sum(tr_ssim) / len(tr_ssim))\n",
    "        # # print(\"Elapsed time = {}\".format(timer() - t_start))\n",
    "        #\n",
    "        # print(\"Validation on train set: epoch [{} / {}], aver PSNR = {:.2f}, aver SSIM = {:.4f}\".format(\n",
    "        #     epoch + 1, epochs, psnr_tr_store[-1], ssim_tr_store[-1]))\n",
    "\n",
    "        # Validate on test set\n",
    "        val_psnr = []\n",
    "        val_ssim = []\n",
    "        with torch.no_grad():\n",
    "            for idx, test_data in enumerate(xs_test):\n",
    "                inputs, labels = test_data\n",
    "                inputs = np.expand_dims(inputs, axis=0)\n",
    "                inputs = torch.from_numpy(inputs).to(device)\n",
    "                labels = labels.squeeze()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.squeeze().cpu().detach().numpy()\n",
    "\n",
    "                val_psnr.append(peak_signal_noise_ratio(labels, outputs))\n",
    "                val_ssim.append(structural_similarity(outputs, labels))\n",
    "\n",
    "        psnr_store.append(sum(val_psnr) / len(val_psnr))\n",
    "        ssim_store.append(sum(val_ssim) / len(val_ssim))\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(psnr_store)\n",
    "        ax.set_title(\"PSNR\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        fig.show()\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(ssim_store)\n",
    "        ax.set_title(\"SSIM\")\n",
    "        ax.set_xlabel(\"epoch\")\n",
    "        fig.show()\n",
    "\n",
    "        print(\"Validation on test set: epoch [{} / {}], aver PSNR = {:.2f}, aver SSIM = {:.4f}\".format(\n",
    "            epoch + 1, epochs, psnr_store[-1], ssim_store[-1]))\n",
    "\n",
    "        # Set model to train mode again.\n",
    "        model = model.train()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Save model\n",
    "        save_model(model, model_save_dir, epoch, dose * 100)\n",
    "\n",
    "        # Save the loss and validation PSNR, SSIM.\n",
    "\n",
    "        if not log_dir.exists():\n",
    "            Path.mkdir(log_dir)\n",
    "        with open(log_file, \"a+\") as fh:\n",
    "            # fh.write(\"{} Epoch [{} / {}], loss = {:.6f}, train PSNR = {:.2f}dB, train SSIM = {:.4f}, \"\n",
    "            #          \"validation PSNR = {:.2f}dB, validation SSIM = {:.4f}\".format(\n",
    "            #          datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),\n",
    "            #          epoch + 1, epochs, epoch_loss_store[-1],\n",
    "            #          psnr_tr_store[-1], ssim_tr_store[-1],\n",
    "            #          psnr_store[-1], ssim_store[-1]))\n",
    "            fh.write(\"{} Epoch [{} / {}], loss = {:.6f}, \"\n",
    "                     \"validation PSNR = {:.2f}dB, validation SSIM = {:.4f}\\n\".format(\n",
    "                     datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),\n",
    "                     epoch + 1, epochs, epoch_loss_store[-1],\n",
    "                     psnr_store[-1], ssim_store[-1]))\n",
    "\n",
    "        # np.savetxt(log_file, np.hstack((epoch + 1, epoch_loss_store[-1], psnr_store[-1], ssim_store[-1])), fmt=\"%.6f\", delimiter=\",  \")\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_store[-len(train_loader):])\n",
    "        ax.set_title(\"Last 1862 losses\")\n",
    "        ax.set_xlabel(\"iteration\")\n",
    "        fig.show()\n",
    "\n",
    "    # print(\"Continue\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data process finished.\n",
      "Epoch [1 / 20], step [0 / 1862], loss = 5.81984, lr = 0.000100, elapsed time = 2.11s\n",
      "Epoch [1 / 20], step [100 / 1862], loss = 0.83258, lr = 0.000100, elapsed time = 32.96s\n",
      "Epoch [1 / 20], step [200 / 1862], loss = 0.77572, lr = 0.000100, elapsed time = 64.55s\n",
      "Epoch [1 / 20], step [300 / 1862], loss = 0.67023, lr = 0.000100, elapsed time = 96.44s\n",
      "Epoch [1 / 20], step [400 / 1862], loss = 0.63575, lr = 0.000100, elapsed time = 128.24s\n",
      "Epoch [1 / 20], step [500 / 1862], loss = 0.57868, lr = 0.000100, elapsed time = 160.24s\n",
      "Epoch [1 / 20], step [600 / 1862], loss = 0.56646, lr = 0.000100, elapsed time = 192.10s\n",
      "Epoch [1 / 20], step [700 / 1862], loss = 0.51471, lr = 0.000100, elapsed time = 223.71s\n",
      "Epoch [1 / 20], step [800 / 1862], loss = 0.50196, lr = 0.000100, elapsed time = 256.57s\n",
      "Epoch [1 / 20], step [900 / 1862], loss = 0.47417, lr = 0.000100, elapsed time = 288.98s\n",
      "Epoch [1 / 20], step [1000 / 1862], loss = 0.45154, lr = 0.000100, elapsed time = 321.46s\n",
      "Epoch [1 / 20], step [1100 / 1862], loss = 0.46988, lr = 0.000100, elapsed time = 353.87s\n",
      "Epoch [1 / 20], step [1200 / 1862], loss = 0.43386, lr = 0.000100, elapsed time = 386.24s\n",
      "Epoch [1 / 20], step [1300 / 1862], loss = 0.44414, lr = 0.000100, elapsed time = 418.74s\n",
      "Epoch [1 / 20], step [1400 / 1862], loss = 0.40133, lr = 0.000100, elapsed time = 451.20s\n",
      "Epoch [1 / 20], step [1500 / 1862], loss = 0.40888, lr = 0.000100, elapsed time = 483.80s\n",
      "Epoch [1 / 20], step [1600 / 1862], loss = 0.39949, lr = 0.000100, elapsed time = 516.22s\n",
      "Epoch [1 / 20], step [1700 / 1862], loss = 0.42160, lr = 0.000100, elapsed time = 548.55s\n",
      "Epoch [1 / 20], step [1800 / 1862], loss = 0.40288, lr = 0.000100, elapsed time = 580.87s\n",
      "Validation on test set: epoch [1 / 20], aver PSNR = 13.44, aver SSIM = 0.5110\n",
      "Saved model checkpoints 1 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_style/dose20\n",
      "Training data process finished.\n",
      "Epoch [2 / 20], step [0 / 1862], loss = 0.41786, lr = 0.000100, elapsed time = 1.53s\n",
      "Epoch [2 / 20], step [100 / 1862], loss = 0.41612, lr = 0.000100, elapsed time = 33.71s\n",
      "Epoch [2 / 20], step [200 / 1862], loss = 0.38597, lr = 0.000100, elapsed time = 65.59s\n",
      "Epoch [2 / 20], step [300 / 1862], loss = 0.41844, lr = 0.000100, elapsed time = 97.47s\n",
      "Epoch [2 / 20], step [400 / 1862], loss = 0.39231, lr = 0.000100, elapsed time = 129.22s\n",
      "Epoch [2 / 20], step [500 / 1862], loss = 0.38678, lr = 0.000100, elapsed time = 161.30s\n",
      "Epoch [2 / 20], step [600 / 1862], loss = 0.38733, lr = 0.000100, elapsed time = 192.83s\n",
      "Epoch [2 / 20], step [700 / 1862], loss = 0.35001, lr = 0.000100, elapsed time = 224.45s\n",
      "Epoch [2 / 20], step [800 / 1862], loss = 0.38513, lr = 0.000100, elapsed time = 256.55s\n",
      "Epoch [2 / 20], step [900 / 1862], loss = 0.37911, lr = 0.000100, elapsed time = 288.81s\n",
      "Epoch [2 / 20], step [1000 / 1862], loss = 0.38432, lr = 0.000100, elapsed time = 320.89s\n",
      "Epoch [2 / 20], step [1100 / 1862], loss = 0.39372, lr = 0.000100, elapsed time = 352.71s\n",
      "Epoch [2 / 20], step [1200 / 1862], loss = 0.34767, lr = 0.000100, elapsed time = 384.51s\n",
      "Epoch [2 / 20], step [1300 / 1862], loss = 0.34125, lr = 0.000100, elapsed time = 416.68s\n",
      "Epoch [2 / 20], step [1400 / 1862], loss = 0.36810, lr = 0.000100, elapsed time = 449.23s\n",
      "Epoch [2 / 20], step [1500 / 1862], loss = 0.39464, lr = 0.000100, elapsed time = 481.82s\n",
      "Epoch [2 / 20], step [1600 / 1862], loss = 0.34583, lr = 0.000100, elapsed time = 514.37s\n",
      "Epoch [2 / 20], step [1700 / 1862], loss = 0.36352, lr = 0.000100, elapsed time = 546.56s\n",
      "Epoch [2 / 20], step [1800 / 1862], loss = 0.36260, lr = 0.000100, elapsed time = 578.05s\n",
      "Validation on test set: epoch [2 / 20], aver PSNR = 13.56, aver SSIM = 0.5464\n",
      "Saved model checkpoints 2 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_style/dose20\n",
      "Training data process finished.\n",
      "Epoch [3 / 20], step [0 / 1862], loss = 0.35627, lr = 0.000100, elapsed time = 1.55s\n",
      "Epoch [3 / 20], step [100 / 1862], loss = 0.37178, lr = 0.000100, elapsed time = 32.96s\n",
      "Epoch [3 / 20], step [200 / 1862], loss = 0.38037, lr = 0.000100, elapsed time = 64.66s\n",
      "Epoch [3 / 20], step [300 / 1862], loss = 0.36053, lr = 0.000100, elapsed time = 96.25s\n",
      "Epoch [3 / 20], step [400 / 1862], loss = 0.34286, lr = 0.000100, elapsed time = 128.02s\n",
      "Epoch [3 / 20], step [500 / 1862], loss = 0.34965, lr = 0.000100, elapsed time = 159.79s\n",
      "Epoch [3 / 20], step [600 / 1862], loss = 0.33452, lr = 0.000100, elapsed time = 191.50s\n",
      "Epoch [3 / 20], step [700 / 1862], loss = 0.36781, lr = 0.000100, elapsed time = 223.25s\n",
      "Epoch [3 / 20], step [800 / 1862], loss = 0.36871, lr = 0.000100, elapsed time = 255.20s\n",
      "Epoch [3 / 20], step [900 / 1862], loss = 0.36123, lr = 0.000100, elapsed time = 287.06s\n",
      "Epoch [3 / 20], step [1000 / 1862], loss = 0.37247, lr = 0.000100, elapsed time = 318.96s\n",
      "Epoch [3 / 20], step [1100 / 1862], loss = 0.36251, lr = 0.000100, elapsed time = 350.61s\n",
      "Epoch [3 / 20], step [1200 / 1862], loss = 0.34878, lr = 0.000100, elapsed time = 382.43s\n",
      "Epoch [3 / 20], step [1300 / 1862], loss = 0.35185, lr = 0.000100, elapsed time = 414.22s\n",
      "Epoch [3 / 20], step [1400 / 1862], loss = 0.34933, lr = 0.000100, elapsed time = 445.85s\n",
      "Epoch [3 / 20], step [1500 / 1862], loss = 0.32478, lr = 0.000100, elapsed time = 477.38s\n",
      "Epoch [3 / 20], step [1600 / 1862], loss = 0.36142, lr = 0.000100, elapsed time = 508.97s\n",
      "Epoch [3 / 20], step [1700 / 1862], loss = 0.37057, lr = 0.000100, elapsed time = 540.59s\n",
      "Epoch [3 / 20], step [1800 / 1862], loss = 0.38613, lr = 0.000100, elapsed time = 572.34s\n",
      "Validation on test set: epoch [3 / 20], aver PSNR = 13.65, aver SSIM = 0.5460\n",
      "Saved model checkpoints 3 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_style/dose20\n",
      "Training data process finished.\n",
      "Epoch [4 / 20], step [0 / 1862], loss = 0.37036, lr = 0.000100, elapsed time = 1.60s\n",
      "Epoch [4 / 20], step [100 / 1862], loss = 0.33490, lr = 0.000100, elapsed time = 33.71s\n",
      "Epoch [4 / 20], step [200 / 1862], loss = 0.32977, lr = 0.000100, elapsed time = 65.62s\n",
      "Epoch [4 / 20], step [300 / 1862], loss = 0.36647, lr = 0.000100, elapsed time = 96.80s\n",
      "Epoch [4 / 20], step [400 / 1862], loss = 0.38577, lr = 0.000100, elapsed time = 128.58s\n",
      "Epoch [4 / 20], step [500 / 1862], loss = 0.35768, lr = 0.000100, elapsed time = 160.12s\n",
      "Epoch [4 / 20], step [600 / 1862], loss = 0.35164, lr = 0.000100, elapsed time = 191.61s\n",
      "Epoch [4 / 20], step [700 / 1862], loss = 0.36966, lr = 0.000100, elapsed time = 223.08s\n",
      "Epoch [4 / 20], step [800 / 1862], loss = 0.35184, lr = 0.000100, elapsed time = 254.54s\n",
      "Epoch [4 / 20], step [900 / 1862], loss = 0.35249, lr = 0.000100, elapsed time = 286.19s\n",
      "Epoch [4 / 20], step [1000 / 1862], loss = 0.33744, lr = 0.000100, elapsed time = 317.83s\n",
      "Epoch [4 / 20], step [1100 / 1862], loss = 0.36187, lr = 0.000100, elapsed time = 349.23s\n",
      "Epoch [4 / 20], step [1200 / 1862], loss = 0.32358, lr = 0.000100, elapsed time = 381.04s\n",
      "Epoch [4 / 20], step [1300 / 1862], loss = 0.34031, lr = 0.000100, elapsed time = 412.89s\n",
      "Epoch [4 / 20], step [1400 / 1862], loss = 0.32360, lr = 0.000100, elapsed time = 444.75s\n",
      "Epoch [4 / 20], step [1500 / 1862], loss = 0.34875, lr = 0.000100, elapsed time = 476.60s\n",
      "Epoch [4 / 20], step [1600 / 1862], loss = 0.35609, lr = 0.000100, elapsed time = 508.12s\n",
      "Epoch [4 / 20], step [1700 / 1862], loss = 0.35749, lr = 0.000100, elapsed time = 539.92s\n",
      "Epoch [4 / 20], step [1800 / 1862], loss = 0.33804, lr = 0.000100, elapsed time = 571.73s\n",
      "Validation on test set: epoch [4 / 20], aver PSNR = 13.57, aver SSIM = 0.5517\n",
      "Saved model checkpoints 4 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_style/dose20\n",
      "Training data process finished.\n",
      "Epoch [5 / 20], step [0 / 1862], loss = 0.34654, lr = 0.000100, elapsed time = 1.57s\n",
      "Epoch [5 / 20], step [100 / 1862], loss = 0.35225, lr = 0.000100, elapsed time = 33.47s\n",
      "Epoch [5 / 20], step [200 / 1862], loss = 0.33514, lr = 0.000100, elapsed time = 65.09s\n",
      "Epoch [5 / 20], step [300 / 1862], loss = 0.35493, lr = 0.000100, elapsed time = 96.83s\n",
      "Epoch [5 / 20], step [400 / 1862], loss = 0.32857, lr = 0.000100, elapsed time = 127.86s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5 / 20], step [500 / 1862], loss = 0.31752, lr = 0.000100, elapsed time = 158.75s\n",
      "Epoch [5 / 20], step [600 / 1862], loss = 0.34314, lr = 0.000100, elapsed time = 189.75s\n",
      "Epoch [5 / 20], step [700 / 1862], loss = 0.34420, lr = 0.000100, elapsed time = 220.96s\n",
      "Epoch [5 / 20], step [800 / 1862], loss = 0.33941, lr = 0.000100, elapsed time = 251.67s\n",
      "Epoch [5 / 20], step [900 / 1862], loss = 0.33868, lr = 0.000100, elapsed time = 281.69s\n",
      "Epoch [5 / 20], step [1000 / 1862], loss = 0.33979, lr = 0.000100, elapsed time = 311.74s\n",
      "Epoch [5 / 20], step [1100 / 1862], loss = 0.34813, lr = 0.000100, elapsed time = 342.18s\n",
      "Epoch [5 / 20], step [1200 / 1862], loss = 0.34164, lr = 0.000100, elapsed time = 372.64s\n",
      "Epoch [5 / 20], step [1300 / 1862], loss = 0.33406, lr = 0.000100, elapsed time = 403.48s\n",
      "Epoch [5 / 20], step [1400 / 1862], loss = 0.33223, lr = 0.000100, elapsed time = 434.72s\n",
      "Epoch [5 / 20], step [1500 / 1862], loss = 0.33687, lr = 0.000100, elapsed time = 465.86s\n",
      "Epoch [5 / 20], step [1600 / 1862], loss = 0.35833, lr = 0.000100, elapsed time = 496.84s\n",
      "Epoch [5 / 20], step [1700 / 1862], loss = 0.33705, lr = 0.000100, elapsed time = 527.77s\n",
      "Epoch [5 / 20], step [1800 / 1862], loss = 0.32984, lr = 0.000100, elapsed time = 558.72s\n",
      "Validation on test set: epoch [5 / 20], aver PSNR = 13.65, aver SSIM = 0.5555\n",
      "Saved model checkpoints 5 into /projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/results/model_path_just_style/dose20\n",
      "Training data process finished.\n",
      "Epoch [6 / 20], step [0 / 1862], loss = 0.34409, lr = 0.000100, elapsed time = 1.59s\n",
      "Epoch [6 / 20], step [100 / 1862], loss = 0.33555, lr = 0.000100, elapsed time = 33.14s\n",
      "Epoch [6 / 20], step [200 / 1862], loss = 0.33888, lr = 0.000100, elapsed time = 64.47s\n",
      "Epoch [6 / 20], step [300 / 1862], loss = 0.34106, lr = 0.000100, elapsed time = 95.95s\n",
      "Epoch [6 / 20], step [400 / 1862], loss = 0.36165, lr = 0.000100, elapsed time = 127.42s\n",
      "Epoch [6 / 20], step [500 / 1862], loss = 0.37505, lr = 0.000100, elapsed time = 158.94s\n",
      "Epoch [6 / 20], step [600 / 1862], loss = 0.34569, lr = 0.000100, elapsed time = 190.42s\n",
      "Epoch [6 / 20], step [700 / 1862], loss = 0.36556, lr = 0.000100, elapsed time = 221.71s\n",
      "Epoch [6 / 20], step [800 / 1862], loss = 0.35485, lr = 0.000100, elapsed time = 252.91s\n",
      "Epoch [6 / 20], step [900 / 1862], loss = 0.30655, lr = 0.000100, elapsed time = 284.08s\n",
      "Epoch [6 / 20], step [1000 / 1862], loss = 0.33150, lr = 0.000100, elapsed time = 315.28s\n",
      "Epoch [6 / 20], step [1100 / 1862], loss = 0.33361, lr = 0.000100, elapsed time = 346.65s\n",
      "Epoch [6 / 20], step [1200 / 1862], loss = 0.34540, lr = 0.000100, elapsed time = 378.11s\n",
      "Epoch [6 / 20], step [1300 / 1862], loss = 0.32527, lr = 0.000100, elapsed time = 408.93s\n",
      "Epoch [6 / 20], step [1400 / 1862], loss = 0.35718, lr = 0.000100, elapsed time = 439.54s\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    config = configparser.ConfigParser()\n",
    "\n",
    "    config.read(\"/projectnb/ec523/mcokbas/Final_project/DnCNN_poisson_perceptual/cfg_just_content.ini\")\n",
    "\n",
    "    train_model(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
